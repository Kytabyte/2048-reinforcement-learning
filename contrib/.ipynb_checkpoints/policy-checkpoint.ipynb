{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import DotDict\n",
    "from memory import Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an Env should record the episode rewards etc.\n",
    "\n",
    "class Env:\n",
    "    def __init__(self, name, stat):\n",
    "        self._name = name\n",
    "        self._env = gym.make(name)\n",
    "        self._stat = stat\n",
    "        self._state = torch.FloatTensor(self._env.reset())\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "    \n",
    "    @property\n",
    "    def state(self):\n",
    "        return self._state\n",
    "    \n",
    "    def step(self, action):\n",
    "        next_state, reward, done, info = self._env.step(action.item())\n",
    "        self._stat.rewards[-1] += reward\n",
    "        if done:\n",
    "            print(self._stat.frame, self._stat.rewards[-1])\n",
    "            self._stat.rewards.append(0)\n",
    "        self._state = torch.FloatTensor(self._env.reset()) if done else torch.FloatTensor(next_state)\n",
    "        return torch.FloatTensor(next_state), torch.tensor(reward), torch.tensor(done), info\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base:\n",
    "    def __init__(self, config):\n",
    "        self._config = DotDict(**config)\n",
    "        self._stat = DotDict(**{\n",
    "            'frame': 0,\n",
    "            'episode': 0,\n",
    "            'rewards': [0]\n",
    "        })\n",
    "        env_name = self._config.env\n",
    "        self._config.env = Env(env_name, self._stat)\n",
    "    \n",
    "    @property\n",
    "    def env(self):\n",
    "        return self._config.env\n",
    "    \n",
    "    @property\n",
    "    def nn(self):\n",
    "        return self._config.nn\n",
    "    \n",
    "    @property\n",
    "    def optim(self):\n",
    "        return self._config.optim\n",
    "    \n",
    "    @property\n",
    "    def scheduler(self):\n",
    "        return self._config.scheduler\n",
    "    \n",
    "    @property\n",
    "    def stat(self):\n",
    "        return self._stat\n",
    "    \n",
    "    @property\n",
    "    def frame(self):\n",
    "        return self._stat.frame\n",
    "    \n",
    "    @property\n",
    "    def episode(self):\n",
    "        return self._stat.episode\n",
    "    \n",
    "    def run(self, n_frames, from_frame=0):\n",
    "        self._stat.frame = from_frame\n",
    "        \n",
    "        while self.frame <= n_frames:\n",
    "            for _ in range(self._config.step_length):\n",
    "                self.step()\n",
    "                self._stat.frame += 1\n",
    "            self.learn()\n",
    "            \n",
    "            if len(self._stat.rewards) >= 100 and sum(self._stat.rewards) / len(self._stat.rewards) >= 195:\n",
    "                print('Solved')\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(4, 20)\n",
    "        self.linear2 = nn.Linear(20, 20)\n",
    "        self.linear3 = nn.Linear(20, 20)\n",
    "        self.linear4 = nn.Linear(20, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = F.relu(self.linear3(x))\n",
    "        return F.softmax(self.linear4(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'env': 'CartPole-v0',\n",
    "    'nn': net,\n",
    "    'optim': optimizer,\n",
    "    'scheduler': None,\n",
    "    'step_length': 20,\n",
    "    'gamma': 0.9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reinforce(Base):\n",
    "    def __init__(self, config):\n",
    "        super(Reinforce, self).__init__(config)\n",
    "        self._memory = Memory(\n",
    "            fields=('log_prob', 'reward', 'done'),\n",
    "            cap=config['step_length'])\n",
    "    \n",
    "    def step(self):\n",
    "        state = self.env.state\n",
    "        policy = self.nn(state)\n",
    "        probs = Categorical(policy)\n",
    "        action = probs.sample()\n",
    "        log_prob = probs.log_prob(action)\n",
    "        next_state, reward, done, info = self.env.step(action)\n",
    "        self._memory.append([log_prob, reward, done.float()])\n",
    "    \n",
    "    def learn(self):\n",
    "        log_probs, rewards, dones = self._memory.flush()\n",
    "        gamma = self._config.gamma\n",
    "        eps = torch.finfo()\n",
    "        \n",
    "        gain = 0\n",
    "        exp_rewards = []\n",
    "        for i in reversed(range(rewards.size(0))):\n",
    "            reward, done = rewards[i], dones[i]\n",
    "            gain = reward + gamma * gain * (1 - done)\n",
    "            exp_rewards.append(gain)\n",
    "        \n",
    "        exp_rewards.reverse()\n",
    "        exp_rewards = torch.stack(exp_rewards)\n",
    "        eps = torch.finfo(exp_rewards.dtype).eps\n",
    "        exp_rewards = (exp_rewards - exp_rewards.mean()) / (exp_rewards.std() + eps)\n",
    "\n",
    "        loss = -(log_probs * exp_rewards).sum()\n",
    "        self.optim.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Reinforce(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 18.0\n",
      "28 25.0\n",
      "48 20.0\n",
      "59 11.0\n",
      "121 62.0\n",
      "148 27.0\n",
      "211 63.0\n",
      "220 9.0\n",
      "237 17.0\n",
      "278 41.0\n",
      "298 20.0\n",
      "319 21.0\n",
      "333 14.0\n",
      "354 21.0\n",
      "374 20.0\n",
      "389 15.0\n",
      "402 13.0\n",
      "418 16.0\n",
      "443 25.0\n",
      "480 37.0\n",
      "496 16.0\n",
      "512 16.0\n",
      "522 10.0\n",
      "532 10.0\n",
      "556 24.0\n",
      "579 23.0\n",
      "589 10.0\n",
      "598 9.0\n",
      "634 36.0\n",
      "671 37.0\n",
      "686 15.0\n",
      "699 13.0\n",
      "740 41.0\n",
      "762 22.0\n",
      "793 31.0\n",
      "803 10.0\n",
      "827 24.0\n",
      "844 17.0\n",
      "884 40.0\n",
      "896 12.0\n",
      "916 20.0\n",
      "960 44.0\n",
      "979 19.0\n",
      "995 16.0\n",
      "1027 32.0\n",
      "1048 21.0\n",
      "1072 24.0\n",
      "1086 14.0\n",
      "1104 18.0\n",
      "1123 19.0\n",
      "1134 11.0\n",
      "1153 19.0\n",
      "1168 15.0\n",
      "1180 12.0\n",
      "1194 14.0\n",
      "1216 22.0\n",
      "1228 12.0\n",
      "1258 30.0\n",
      "1267 9.0\n",
      "1279 12.0\n",
      "1293 14.0\n",
      "1319 26.0\n",
      "1422 103.0\n",
      "1440 18.0\n",
      "1454 14.0\n",
      "1473 19.0\n",
      "1494 21.0\n",
      "1508 14.0\n",
      "1528 20.0\n",
      "1548 20.0\n",
      "1600 52.0\n",
      "1619 19.0\n",
      "1633 14.0\n",
      "1652 19.0\n",
      "1675 23.0\n",
      "1687 12.0\n",
      "1715 28.0\n",
      "1738 23.0\n",
      "1785 47.0\n",
      "1801 16.0\n",
      "1817 16.0\n",
      "1870 53.0\n",
      "1890 20.0\n",
      "1946 56.0\n",
      "1961 15.0\n",
      "1985 24.0\n",
      "2023 38.0\n",
      "2037 14.0\n",
      "2048 11.0\n",
      "2062 14.0\n",
      "2075 13.0\n",
      "2091 16.0\n",
      "2115 24.0\n",
      "2139 24.0\n",
      "2150 11.0\n",
      "2163 13.0\n",
      "2177 14.0\n",
      "2190 13.0\n",
      "2212 22.0\n",
      "2243 31.0\n",
      "2264 21.0\n",
      "2293 29.0\n",
      "2304 11.0\n",
      "2321 17.0\n",
      "2342 21.0\n",
      "2368 26.0\n",
      "2397 29.0\n",
      "2413 16.0\n",
      "2447 34.0\n",
      "2482 35.0\n",
      "2512 30.0\n",
      "2525 13.0\n",
      "2544 19.0\n",
      "2564 20.0\n",
      "2583 19.0\n",
      "2608 25.0\n",
      "2627 19.0\n",
      "2636 9.0\n",
      "2659 23.0\n",
      "2670 11.0\n",
      "2690 20.0\n",
      "2740 50.0\n",
      "2767 27.0\n",
      "2779 12.0\n",
      "2843 64.0\n",
      "2859 16.0\n",
      "2872 13.0\n",
      "2883 11.0\n",
      "2905 22.0\n",
      "2924 19.0\n",
      "2957 33.0\n",
      "2988 31.0\n",
      "2997 9.0\n",
      "3009 12.0\n",
      "3061 52.0\n",
      "3090 29.0\n",
      "3110 20.0\n",
      "3127 17.0\n",
      "3148 21.0\n",
      "3167 19.0\n",
      "3179 12.0\n",
      "3202 23.0\n",
      "3240 38.0\n",
      "3254 14.0\n",
      "3279 25.0\n",
      "3300 21.0\n",
      "3325 25.0\n",
      "3341 16.0\n",
      "3354 13.0\n",
      "3383 29.0\n",
      "3401 18.0\n",
      "3441 40.0\n",
      "3456 15.0\n",
      "3476 20.0\n",
      "3516 40.0\n",
      "3531 15.0\n",
      "3558 27.0\n",
      "3570 12.0\n",
      "3591 21.0\n",
      "3606 15.0\n",
      "3627 21.0\n",
      "3636 9.0\n",
      "3662 26.0\n",
      "3671 9.0\n",
      "3682 11.0\n",
      "3693 11.0\n",
      "3705 12.0\n",
      "3745 40.0\n",
      "3775 30.0\n",
      "3784 9.0\n",
      "3797 13.0\n",
      "3807 10.0\n",
      "3818 11.0\n",
      "3856 38.0\n",
      "3864 8.0\n",
      "3908 44.0\n",
      "3936 28.0\n",
      "3961 25.0\n",
      "3985 24.0\n",
      "4004 19.0\n",
      "4021 17.0\n",
      "4046 25.0\n",
      "4066 20.0\n",
      "4077 11.0\n",
      "4102 25.0\n",
      "4118 16.0\n",
      "4130 12.0\n",
      "4149 19.0\n",
      "4165 16.0\n",
      "4197 32.0\n",
      "4212 15.0\n",
      "4234 22.0\n",
      "4245 11.0\n",
      "4267 22.0\n",
      "4276 9.0\n",
      "4311 35.0\n",
      "4327 16.0\n",
      "4355 28.0\n",
      "4392 37.0\n",
      "4414 22.0\n",
      "4432 18.0\n",
      "4454 22.0\n",
      "4466 12.0\n",
      "4516 50.0\n",
      "4538 22.0\n",
      "4588 50.0\n",
      "4600 12.0\n",
      "4612 12.0\n",
      "4638 26.0\n",
      "4652 14.0\n",
      "4671 19.0\n",
      "4702 31.0\n",
      "4717 15.0\n",
      "4727 10.0\n",
      "4750 23.0\n",
      "4792 42.0\n",
      "4810 18.0\n",
      "4855 45.0\n",
      "4876 21.0\n",
      "4901 25.0\n",
      "4930 29.0\n",
      "4951 21.0\n",
      "4968 17.0\n",
      "4981 13.0\n",
      "4995 14.0\n",
      "5010 15.0\n",
      "5032 22.0\n",
      "5060 28.0\n",
      "5123 63.0\n",
      "5154 31.0\n",
      "5177 23.0\n",
      "5250 73.0\n",
      "5272 22.0\n",
      "5309 37.0\n",
      "5321 12.0\n",
      "5339 18.0\n",
      "5357 18.0\n",
      "5394 37.0\n",
      "5416 22.0\n",
      "5441 25.0\n",
      "5462 21.0\n",
      "5524 62.0\n",
      "5535 11.0\n",
      "5568 33.0\n",
      "5592 24.0\n",
      "5603 11.0\n",
      "5614 11.0\n",
      "5630 16.0\n",
      "5643 13.0\n",
      "5653 10.0\n",
      "5668 15.0\n",
      "5678 10.0\n",
      "5691 13.0\n",
      "5720 29.0\n",
      "5733 13.0\n",
      "5745 12.0\n",
      "5755 10.0\n",
      "5775 20.0\n",
      "5790 15.0\n",
      "5809 19.0\n",
      "5824 15.0\n",
      "5833 9.0\n",
      "5845 12.0\n",
      "5874 29.0\n",
      "5888 14.0\n",
      "5908 20.0\n",
      "5941 33.0\n",
      "5951 10.0\n",
      "5973 22.0\n",
      "5991 18.0\n",
      "6022 31.0\n",
      "6072 50.0\n",
      "6087 15.0\n",
      "6123 36.0\n",
      "6153 30.0\n",
      "6177 24.0\n",
      "6200 23.0\n",
      "6210 10.0\n",
      "6224 14.0\n",
      "6238 14.0\n",
      "6265 27.0\n",
      "6294 29.0\n",
      "6305 11.0\n",
      "6330 25.0\n",
      "6351 21.0\n",
      "6375 24.0\n",
      "6388 13.0\n",
      "6403 15.0\n",
      "6416 13.0\n",
      "6459 43.0\n",
      "6480 21.0\n",
      "6516 36.0\n",
      "6543 27.0\n",
      "6604 61.0\n",
      "6616 12.0\n",
      "6657 41.0\n",
      "6669 12.0\n",
      "6677 8.0\n",
      "6689 12.0\n",
      "6728 39.0\n",
      "6750 22.0\n",
      "6762 12.0\n",
      "6778 16.0\n",
      "6797 19.0\n",
      "6834 37.0\n",
      "6853 19.0\n",
      "6865 12.0\n",
      "6881 16.0\n",
      "6892 11.0\n",
      "6905 13.0\n",
      "6938 33.0\n",
      "6955 17.0\n",
      "6982 27.0\n",
      "6999 17.0\n",
      "7012 13.0\n",
      "7036 24.0\n",
      "7047 11.0\n",
      "7064 17.0\n",
      "7082 18.0\n",
      "7108 26.0\n",
      "7128 20.0\n",
      "7153 25.0\n",
      "7173 20.0\n",
      "7185 12.0\n",
      "7195 10.0\n",
      "7213 18.0\n",
      "7253 40.0\n",
      "7269 16.0\n",
      "7290 21.0\n",
      "7308 18.0\n",
      "7335 27.0\n",
      "7365 30.0\n",
      "7377 12.0\n",
      "7393 16.0\n",
      "7418 25.0\n",
      "7452 34.0\n",
      "7462 10.0\n",
      "7476 14.0\n",
      "7511 35.0\n",
      "7524 13.0\n",
      "7548 24.0\n",
      "7560 12.0\n",
      "7579 19.0\n",
      "7597 18.0\n",
      "7607 10.0\n",
      "7619 12.0\n",
      "7674 55.0\n",
      "7694 20.0\n",
      "7705 11.0\n",
      "7726 21.0\n",
      "7742 16.0\n",
      "7768 26.0\n",
      "7787 19.0\n",
      "7807 20.0\n",
      "7818 11.0\n",
      "7866 48.0\n",
      "7928 62.0\n",
      "7947 19.0\n",
      "7972 25.0\n",
      "7991 19.0\n",
      "8014 23.0\n",
      "8043 29.0\n",
      "8083 40.0\n",
      "8102 19.0\n",
      "8116 14.0\n",
      "8154 38.0\n",
      "8165 11.0\n",
      "8191 26.0\n",
      "8211 20.0\n",
      "8252 41.0\n",
      "8271 19.0\n",
      "8288 17.0\n",
      "8300 12.0\n",
      "8325 25.0\n",
      "8341 16.0\n",
      "8360 19.0\n",
      "8377 17.0\n",
      "8394 17.0\n",
      "8425 31.0\n",
      "8436 11.0\n",
      "8448 12.0\n",
      "8468 20.0\n",
      "8492 24.0\n",
      "8508 16.0\n",
      "8550 42.0\n",
      "8586 36.0\n",
      "8616 30.0\n",
      "8628 12.0\n",
      "8642 14.0\n",
      "8707 65.0\n",
      "8749 42.0\n",
      "8766 17.0\n",
      "8798 32.0\n",
      "8833 35.0\n",
      "8844 11.0\n",
      "8872 28.0\n",
      "8884 12.0\n",
      "8919 35.0\n",
      "8932 13.0\n",
      "8944 12.0\n",
      "8957 13.0\n",
      "8974 17.0\n",
      "8989 15.0\n",
      "9004 15.0\n",
      "9018 14.0\n",
      "9032 14.0\n",
      "9043 11.0\n",
      "9060 17.0\n",
      "9075 15.0\n",
      "9086 11.0\n",
      "9123 37.0\n",
      "9156 33.0\n",
      "9173 17.0\n",
      "9228 55.0\n",
      "9267 39.0\n",
      "9294 27.0\n",
      "9305 11.0\n",
      "9335 30.0\n",
      "9387 52.0\n",
      "9414 27.0\n",
      "9436 22.0\n",
      "9468 32.0\n",
      "9487 19.0\n",
      "9505 18.0\n",
      "9546 41.0\n",
      "9561 15.0\n",
      "9604 43.0\n",
      "9621 17.0\n",
      "9640 19.0\n",
      "9666 26.0\n",
      "9685 19.0\n",
      "9705 20.0\n",
      "9735 30.0\n",
      "9753 18.0\n",
      "9766 13.0\n",
      "9789 23.0\n",
      "9806 17.0\n",
      "9886 80.0\n",
      "9935 49.0\n",
      "9978 43.0\n",
      "9988 10.0\n",
      "10002 14.0\n"
     ]
    }
   ],
   "source": [
    "agent.run(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  utils\n",
    "\"\"\"\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "const = DotDict(\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    MACHINE_EPS = np.finfo(np.float32).eps.item()\n",
    ")\n",
    "\n",
    "def astensor(obj, to_type=None):\n",
    "  \"\"\"\n",
    "    to_type selected from 'int', 'long', 'float', 'double', and 'byte'\n",
    "\n",
    "    not responsible for handling type cast error\n",
    "  \"\"\"\n",
    "  if to_type is None:\n",
    "    return torch.tensor(obj).to(const.DEVICE) if not isinstance(obj, torch.Tensor) else obj\n",
    "  elif to_type == 'int':\n",
    "    return torch.IntTensor(obj).to(const.DEVICE) if not isinstance(obj, torch.Tensor) else obj.int()\n",
    "  elif to_type == 'long':\n",
    "    return torch.LongTensor(obj).to(const.DEVICE) if not isinstance(obj, torch.Tensor) else obj.long()\n",
    "  elif to_type == 'float':\n",
    "    return torch.FloatTensor(obj).to(const.DEVICE) if not isinstance(obj, torch.Tensor) else obj.float()\n",
    "  elif to_type == 'double':\n",
    "    return torch.DoubleTensor(obj).to(const.DEVICE) if not isinstance(obj, torch.Tensor) else obj.double()\n",
    "  elif to_type == 'byte':\n",
    "    return torch.ByteTensor(obj).to(const.DEVICE) if not isinstance(obj, torch.Tensor) else obj.byte()\n",
    "  else:\n",
    "    raise TypeError(\n",
    "      '''\n",
    "        to_type can only be one of \n",
    "        'int', 'long', 'float', 'double', 'byte'\n",
    "        or leave empty.\n",
    "      '''\n",
    "      )\n",
    "\n",
    "def copynet(network):\n",
    "  \"\"\"\n",
    "    a deepcopy of a network \n",
    "  \"\"\"\n",
    "  if not isinstance(network, nn.Module):\n",
    "    raise TypeError('Input must be a instance of {}, but got {}'.format(nn.Module, network.__class__.__name__))\n",
    "\n",
    "  return copy.deepcopy(network)\n",
    "\n",
    "\n",
    "def flatten(network, input_size):\n",
    "  \"\"\"\n",
    "    return the number of features after applying `network`structure on a network with\n",
    "    shape `input_size`\n",
    "  \"\"\"\n",
    "  if not isinstance(network, nn.Module):\n",
    "    network = nn.Sequential(\n",
    "        *network\n",
    "    )\n",
    "\n",
    "  with torch.no_grad():\n",
    "    num_features = network(torch.rand((1, *input_size))).view(1, -1).size(1)\n",
    "\n",
    "  return num_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-182-d57423bcf697>, line 104)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-182-d57423bcf697>\"\u001b[0;36m, line \u001b[0;32m104\u001b[0m\n\u001b[0;31m    else:\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "class PolicyNet(object):\n",
    "    \"\"\"\n",
    "      REINFORCE algorithm implementation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, net, obs_shape, n_act, target=False):\n",
    "        self._net = net\n",
    "        self._obs_shape, self._n_act = obs_shape, n_act\n",
    "        if target:\n",
    "            self._tnet = copynet(self._net)\n",
    "            self._tnet.load_state_dict(self._net.state_dict())\n",
    "        else:\n",
    "            self._tnet = None\n",
    "\n",
    "        self.logprobs = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "\n",
    "    def act(self, obs, act_mask=None):\n",
    "        act_mask = astensor(act_mask,\n",
    "                            'float') if act_mask is not None else astensor(\n",
    "            [1] * self._n_act, 'float')\n",
    "\n",
    "        probs = self.forward(obs) * act_mask.unsqueeze(0) + const.MACHINE_EPS\n",
    "        distribution = Categorical(probs)\n",
    "        action = distribution.sample()\n",
    "        self.logprobs.append(distribution.log_prob(action))\n",
    "\n",
    "        return action.cpu().item()\n",
    "\n",
    "    def forward(self, obs):\n",
    "        if not isinstance(obs, torch.Tensor):\n",
    "            obs = astensor(obs, 'float')\n",
    "        obs.reshape(obs.size(0), *self._obs_shape)\n",
    "        if self._tnet:\n",
    "            return F.softmax(self._tnet(obs), dim=1)\n",
    "        return F.softmax(self._net(obs), dim=1)\n",
    "\n",
    "    def learn(self, optimizer=None, gamma=0.99):\n",
    "        assert self.logprobs and self.rewards and self.dones\n",
    "        assert len(self.logprobs) == len(self.rewards) == len(self.dones)\n",
    "\n",
    "        if optimizer is None:\n",
    "            optimizer = optim.Adam(self.parameters())\n",
    "\n",
    "        discounted_rewards = self._discount(gamma)\n",
    "        loss = self._loss(discounted_rewards)\n",
    "        self._learn(optimizer, loss)\n",
    "\n",
    "    def parameters(self):\n",
    "        return self._net.parameters()\n",
    "\n",
    "    def update_tnet(self, soft_tau=1e-2):\n",
    "        if self._tnet:\n",
    "            for target_param, param in zip(self._tnet.parameters(),\n",
    "                                           self._net.parameters()):\n",
    "                target_param.data.copy_(target_param.data * (1 - soft_tau) +\n",
    "                                        param.data * soft_tau)\n",
    "        else:\n",
    "            print(\n",
    "                'You did not initialize target network, please check your network structure.'\n",
    "            )\n",
    "\n",
    "    def _discount(self, gamma, init_gain=0):\n",
    "        gain = init_gain\n",
    "        discounted_rewards = []\n",
    "        while self.rewards:\n",
    "            reward, done = self.rewards.pop(), self.dones.pop()\n",
    "            gain = reward + gamma * gain * (1 - done)\n",
    "            discounted_rewards.append(gain)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            discounted_rewards = astensor(discounted_rewards)\n",
    "            discounted_rewards = (discounted_rewards - discounted_rewards.mean()) / (\n",
    "                    discounted_rewards.std() + const.MACHINE_EPS)\n",
    "\n",
    "        return discounted_rewards\n",
    "\n",
    "    def _loss(self, rewards):\n",
    "        loss = []\n",
    "        for reward in rewards:\n",
    "            logprob = self.logprobs.pop()\n",
    "            loss.append(-logprob * reward)\n",
    "            loss = torch.cat(loss).sum()\n",
    "        return loss\n",
    "\n",
    "    @staticmethod\n",
    "    def _learn(optimizer, loss):\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    def run(self, n_frame):\n",
    "        env = gym.make('CartPole-v0')\n",
    "        state = env.reset()\n",
    "        cur_frame = 0\n",
    "        while cur_frame < n_frame:\n",
    "            action = self.act(state)\n",
    "            next_state, reward, done, _ = env.step()\n",
    "            self.rewards.append(reward)\n",
    "            self.dones.append(done)\n",
    "            if done:\n",
    "                state = env.reset()\n",
    "            else:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(4, 20)\n",
    "        self.linear2 = nn.Linear(20, 20)\n",
    "        self.linear3 = nn.Linear(20, 20)\n",
    "        self.linear4 = nn.Linear(20, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = F.relu(self.linear3(x))\n",
    "        return F.softmax(self.linear4(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "policynet = PolicyNet(Net(), (4,), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
