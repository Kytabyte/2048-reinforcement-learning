{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import DotDict\n",
    "from memory import Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an Env should record the episode rewards etc.\n",
    "\n",
    "class Env:\n",
    "    def __init__(self, name, stat):\n",
    "        self._name = name\n",
    "        self._env = gym.make(name)\n",
    "        self._stat = stat\n",
    "        self._state = torch.FloatTensor(self._env.reset())\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "    \n",
    "    @property\n",
    "    def state(self):\n",
    "        return self._state\n",
    "    \n",
    "    def step(self, action):\n",
    "        next_state, reward, done, info = self._env.step(action.item())\n",
    "        self._stat.rewards[-1] += reward\n",
    "        if done:\n",
    "            print(self._stat.frame, self._stat.rewards[-1])\n",
    "            self._stat.rewards.append(0)\n",
    "        self._state = torch.FloatTensor(self._env.reset()) if done else torch.FloatTensor(next_state)\n",
    "        return torch.FloatTensor(next_state), torch.tensor(reward), torch.tensor(done), info\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(4, 20)\n",
    "        self.linear2 = nn.Linear(20, 20)\n",
    "        self.linear3 = nn.Linear(20, 20)\n",
    "        self.linear4 = nn.Linear(20, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = F.relu(self.linear3(x))\n",
    "        return F.softmax(self.linear4(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base:\n",
    "    def __init__(self, config):\n",
    "        self._config = DotDict(**config)\n",
    "        self._stat = DotDict(**{\n",
    "            'frame': 0,\n",
    "            'episode': 0,\n",
    "            'rewards': [0]\n",
    "        })\n",
    "        env_name = self._config.env\n",
    "        self._config.env = Env(env_name, self._stat)\n",
    "    \n",
    "    @property\n",
    "    def env(self):\n",
    "        return self._config.env\n",
    "    \n",
    "    @property\n",
    "    def nn(self):\n",
    "        return self._config.nn\n",
    "    \n",
    "    @property\n",
    "    def optim(self):\n",
    "        return self._config.optim\n",
    "    \n",
    "    @property\n",
    "    def scheduler(self):\n",
    "        return self._config.scheduler\n",
    "    \n",
    "    @property\n",
    "    def stat(self):\n",
    "        return self._stat\n",
    "    \n",
    "    @property\n",
    "    def frame(self):\n",
    "        return self._stat.frame\n",
    "    \n",
    "    @property\n",
    "    def episode(self):\n",
    "        return self._stat.episode\n",
    "    \n",
    "    def run(self, n_frames, from_frame=0):\n",
    "        self._stat.frame = from_frame\n",
    "        \n",
    "        while self.frame <= n_frames:\n",
    "            for _ in range(self._config.step_length):\n",
    "                self.step()\n",
    "                self._stat.frame += 1\n",
    "            self.learn()\n",
    "            \n",
    "            if len(self._stat.rewards) >= 100 and sum(self._stat.rewards) / len(self._stat.rewards) >= 195:\n",
    "                print('Solved')\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REINFORCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reinforce(Base):\n",
    "    def __init__(self, config):\n",
    "        super(Reinforce, self).__init__(config)\n",
    "        self._memory = Memory(\n",
    "            fields=('log_prob', 'reward', 'done'),\n",
    "            cap=config['step_length'])\n",
    "    \n",
    "    def step(self):\n",
    "        state = self.env.state\n",
    "        policy = self.nn(state)\n",
    "        probs = Categorical(policy)\n",
    "        action = probs.sample()\n",
    "        log_prob = probs.log_prob(action)\n",
    "        next_state, reward, done, info = self.env.step(action)\n",
    "        self._memory.append([log_prob, reward, done.float()])\n",
    "    \n",
    "    def learn(self):\n",
    "        log_probs, rewards, dones = self._memory.flush()\n",
    "        gamma = self._config.gamma\n",
    "        eps = torch.finfo()\n",
    "        \n",
    "        gain = 0\n",
    "        exp_rewards = []\n",
    "        for i in reversed(range(rewards.size(0))):\n",
    "            reward, done = rewards[i], dones[i]\n",
    "            gain = reward + gamma * gain * (1 - done)\n",
    "            exp_rewards.append(gain)\n",
    "        \n",
    "        exp_rewards.reverse()\n",
    "        exp_rewards = torch.stack(exp_rewards)\n",
    "        eps = torch.finfo(exp_rewards.dtype).eps\n",
    "        exp_rewards = (exp_rewards - exp_rewards.mean()) / (exp_rewards.std() + eps)\n",
    "\n",
    "        loss = -(log_probs * exp_rewards).sum()\n",
    "        self.optim.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'env': 'CartPole-v0',\n",
    "    'nn': net,\n",
    "    'optim': optimizer,\n",
    "    'scheduler': None,\n",
    "    'step_length': 20,\n",
    "    'gamma': 0.9\n",
    "}\n",
    "\n",
    "net = Net()\n",
    "optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Reinforce(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 63.0\n",
      "142 126.0\n",
      "243 101.0\n",
      "331 88.0\n",
      "407 76.0\n",
      "476 69.0\n",
      "629 153.0\n",
      "741 112.0\n",
      "875 134.0\n",
      "960 85.0\n",
      "1029 69.0\n",
      "1191 162.0\n",
      "1268 77.0\n",
      "1334 66.0\n",
      "1381 47.0\n",
      "1466 85.0\n",
      "1537 71.0\n",
      "1640 103.0\n",
      "1722 82.0\n",
      "1893 171.0\n",
      "1934 41.0\n",
      "1981 47.0\n",
      "2021 40.0\n",
      "2079 58.0\n",
      "2119 40.0\n",
      "2156 37.0\n",
      "2232 76.0\n",
      "2261 29.0\n",
      "2323 62.0\n",
      "2348 25.0\n",
      "2390 42.0\n",
      "2403 13.0\n",
      "2429 26.0\n",
      "2467 38.0\n",
      "2547 80.0\n",
      "2579 32.0\n",
      "2643 64.0\n",
      "2714 71.0\n",
      "2854 140.0\n",
      "2896 42.0\n",
      "3002 106.0\n",
      "3126 124.0\n",
      "3177 51.0\n",
      "3239 62.0\n",
      "3292 53.0\n",
      "3350 58.0\n",
      "3441 91.0\n",
      "3575 134.0\n",
      "3609 34.0\n",
      "3654 45.0\n",
      "3711 57.0\n",
      "3763 52.0\n",
      "3809 46.0\n",
      "3841 32.0\n",
      "3887 46.0\n",
      "3945 58.0\n",
      "3989 44.0\n",
      "4019 30.0\n",
      "4076 57.0\n",
      "4131 55.0\n",
      "4187 56.0\n",
      "4246 59.0\n",
      "4329 83.0\n",
      "4365 36.0\n",
      "4390 25.0\n",
      "4442 52.0\n",
      "4501 59.0\n",
      "4565 64.0\n",
      "4645 80.0\n",
      "4687 42.0\n",
      "4730 43.0\n",
      "4791 61.0\n",
      "4872 81.0\n",
      "4940 68.0\n",
      "4991 51.0\n",
      "5031 40.0\n",
      "5068 37.0\n",
      "5103 35.0\n",
      "5180 77.0\n",
      "5206 26.0\n",
      "5288 82.0\n",
      "5386 98.0\n",
      "5425 39.0\n",
      "5444 19.0\n",
      "5505 61.0\n",
      "5559 54.0\n",
      "5663 104.0\n",
      "5705 42.0\n",
      "5776 71.0\n",
      "5804 28.0\n",
      "5858 54.0\n",
      "5891 33.0\n",
      "5950 59.0\n",
      "5973 23.0\n",
      "6012 39.0\n",
      "6049 37.0\n",
      "6079 30.0\n",
      "6124 45.0\n",
      "6140 16.0\n",
      "6199 59.0\n",
      "6243 44.0\n",
      "6283 40.0\n",
      "6333 50.0\n",
      "6367 34.0\n",
      "6397 30.0\n",
      "6434 37.0\n",
      "6455 21.0\n",
      "6480 25.0\n",
      "6511 31.0\n",
      "6547 36.0\n",
      "6582 35.0\n",
      "6599 17.0\n",
      "6652 53.0\n",
      "6679 27.0\n",
      "6702 23.0\n",
      "6727 25.0\n",
      "6768 41.0\n",
      "6791 23.0\n",
      "6813 22.0\n",
      "6867 54.0\n",
      "6938 71.0\n",
      "7014 76.0\n",
      "7069 55.0\n",
      "7108 39.0\n",
      "7182 74.0\n",
      "7263 81.0\n",
      "7325 62.0\n",
      "7525 200.0\n",
      "7641 116.0\n",
      "7724 83.0\n",
      "7924 200.0\n",
      "8124 200.0\n",
      "8324 200.0\n",
      "8524 200.0\n",
      "8662 138.0\n",
      "8862 200.0\n",
      "8972 110.0\n",
      "9172 200.0\n",
      "9339 167.0\n",
      "9539 200.0\n",
      "9627 88.0\n",
      "9706 79.0\n",
      "9776 70.0\n",
      "9838 62.0\n",
      "9941 103.0\n",
      "10040 99.0\n",
      "10093 53.0\n",
      "10261 168.0\n",
      "10379 118.0\n",
      "10511 132.0\n",
      "10711 200.0\n",
      "10822 111.0\n",
      "10921 99.0\n",
      "11022 101.0\n",
      "11117 95.0\n",
      "11317 200.0\n",
      "11391 74.0\n",
      "11591 200.0\n",
      "11791 200.0\n",
      "11914 123.0\n",
      "12047 133.0\n",
      "12115 68.0\n",
      "12200 85.0\n",
      "12267 67.0\n",
      "12344 77.0\n",
      "12422 78.0\n",
      "12491 69.0\n",
      "12576 85.0\n",
      "12630 54.0\n",
      "12704 74.0\n",
      "12767 63.0\n",
      "12802 35.0\n",
      "12832 30.0\n",
      "12936 104.0\n",
      "12979 43.0\n",
      "13003 24.0\n",
      "13048 45.0\n",
      "13104 56.0\n",
      "13169 65.0\n",
      "13246 77.0\n",
      "13308 62.0\n",
      "13380 72.0\n",
      "13430 50.0\n",
      "13509 79.0\n",
      "13562 53.0\n",
      "13600 38.0\n",
      "13644 44.0\n",
      "13696 52.0\n",
      "13753 57.0\n",
      "13815 62.0\n",
      "13853 38.0\n",
      "13896 43.0\n",
      "13986 90.0\n",
      "14027 41.0\n",
      "14052 25.0\n",
      "14104 52.0\n",
      "14140 36.0\n",
      "14194 54.0\n",
      "14227 33.0\n",
      "14277 50.0\n",
      "14321 44.0\n",
      "14355 34.0\n",
      "14409 54.0\n",
      "14442 33.0\n",
      "14496 54.0\n",
      "14546 50.0\n",
      "14590 44.0\n",
      "14655 65.0\n",
      "14691 36.0\n",
      "14742 51.0\n",
      "14789 47.0\n",
      "14845 56.0\n",
      "14907 62.0\n",
      "14978 71.0\n",
      "15030 52.0\n",
      "15098 68.0\n",
      "15174 76.0\n",
      "15235 61.0\n",
      "15274 39.0\n",
      "15355 81.0\n",
      "15431 76.0\n",
      "15506 75.0\n",
      "15605 99.0\n",
      "15686 81.0\n",
      "15777 91.0\n",
      "15977 200.0\n",
      "16100 123.0\n",
      "16300 200.0\n",
      "16470 170.0\n",
      "16642 172.0\n",
      "16755 113.0\n",
      "16893 138.0\n",
      "16992 99.0\n",
      "17192 200.0\n",
      "17392 200.0\n",
      "17544 152.0\n",
      "17744 200.0\n",
      "17944 200.0\n",
      "18115 171.0\n",
      "18315 200.0\n",
      "18515 200.0\n",
      "18658 143.0\n",
      "18812 154.0\n",
      "19012 200.0\n",
      "19100 88.0\n",
      "19300 200.0\n",
      "19479 179.0\n",
      "19584 105.0\n",
      "19705 121.0\n",
      "19873 168.0\n"
     ]
    }
   ],
   "source": [
    "agent.run(20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actor Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCriticTailNet(nn.Module):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
